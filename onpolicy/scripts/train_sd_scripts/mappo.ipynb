{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MAPPO Integration\n",
    "\n",
    "This runs the integrated MAPPO algorithm with the patrolling zoo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "from onpolicy.scripts.train.train_sd import get_config, parse_args, main\n",
    "\n",
    "import os\n",
    "os.environ[\"WANDB__SERVICE_WAIT\"] = \"300\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "parser = get_config()\n",
    "all_args = parse_args([], parser)\n",
    "\n",
    "all_args.experiment_name = \"metric-test\"\n",
    "all_args.env_name = \"search-deliver\"\n",
    "all_args.user_name = \"ideas-mas\"\n",
    "\n",
    "all_args.num_agents = 4\n",
    "all_args.agent_speed = 40.0\n",
    "all_args.action_method = \"neighbors\"\n",
    "all_args.observe_method = \"pyg\"\n",
    "all_args.observe_method_global = \"adjacency\"\n",
    "all_args.observation_radius = 40.0\n",
    "all_args.observation_bitmap_size = 40\n",
    "all_args.communication_model = \"bernoulli\"\n",
    "all_args.communication_probability = 0.1\n",
    "all_args.alpha = 1.2\n",
    "all_args.beta = 1.0\n",
    "\n",
    "\n",
    "all_args.drop_reward = 1.0\n",
    "all_args.load_reward = 1.0\n",
    "all_args.step_reward = 0.0\n",
    "all_args.state_reward = 1.0\n",
    "all_args.agent_max_capacity = 1\n",
    "# all_args.reward_method_terminal = \"averageAverage\"\n",
    "all_args.reward_method_terminal = \"average\"\n",
    "# all_args.reward_interval = 1\n",
    "\n",
    "# all_args.graph_random = True\n",
    "# all_args.graph_random_nodes = 9\n",
    "all_args.graph_name = \"9nodes\"\n",
    "all_args.graph_file = f\"../../../sdzoo/env/{all_args.graph_name}.graph\"\n",
    "# all_args.num_env_steps = 10000 #total number of steps\n",
    "all_args.num_env_steps = 5000 #1e5 * 2.5 #total number of steps\n",
    "all_args.episode_length = 20 #number of steps in a training episode\n",
    "all_args.max_cycles = all_args.episode_length #number of steps in an environment episode\n",
    "\n",
    "all_args.algorithm_name = \"mappo\"\n",
    "all_args.use_gnn_policy = True\n",
    "all_args.use_gnn_mlp_policy = True\n",
    "all_args.gnn_layer_N = 6\n",
    "all_args.gnn_hidden_size = 128\n",
    "all_args.gnn_skip_connections = True\n",
    "all_args.use_recurrent_policy = True\n",
    "all_args.use_naive_recurrent_policy = False\n",
    "all_args.use_centralized_V = True\n",
    "all_args.use_gae = False\n",
    "all_args.use_gae_amadm = True\n",
    "all_args.share_policy = True\n",
    "all_args.sep_share_policy = False\n",
    "all_args.share_reward = False\n",
    "all_args.skip_steps_sync = True # these need to be false to use max cycles\n",
    "all_args.skip_steps_async = False\n",
    "all_args.use_ReLU = True\n",
    "# all_args.lr = 1e-3\n",
    "# all_args.entropy_coef = 0.1\n",
    "all_args.hidden_size = 512\n",
    "\n",
    "all_args.n_rollout_threads = 1\n",
    "all_args.save_interval = 1000\n",
    "all_args.cuda = False\n",
    "all_args.cuda_idx = 3\n",
    "\n",
    "all_args.use_wandb = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "u are choosing to use mappo, we set use_recurrent_policy & use_naive_recurrent_policy to be False\n",
      "choose to use cpu...\n",
      "Total Deficit: 25\n",
      "Total Surplus: 24\n",
      "AGENT ID: 0\n",
      "Agent 0 Payloads: 0\n",
      "Agent 0 Max Capacity: 1\n",
      "Total Deficit: 25\n",
      "Total Surplus: 24\n",
      "AGENT ID: 1\n",
      "Agent 1 Payloads: 1\n",
      "Agent 1 Max Capacity: 1\n",
      "Total Deficit: 25\n",
      "Total Surplus: 24\n",
      "AGENT ID: 2\n",
      "Agent 2 Payloads: 0\n",
      "Agent 2 Max Capacity: 1\n",
      "Total Deficit: 25\n",
      "Total Surplus: 24\n",
      "AGENT ID: 3\n",
      "Agent 3 Payloads: 0\n",
      "Agent 3 Max Capacity: 1\n",
      "\n",
      " Env search-deliver Algo mappo Exp metric-test updates 0/250 episodes, total num timesteps 20/5000, FPS 6.\n",
      "\n",
      "average episode rewards is -0.962500125169754\n",
      "Total Deficit: 25\n",
      "Total Surplus: 23\n",
      "AGENT ID: 0\n",
      "Agent 0 Payloads: 0\n",
      "Agent 0 Max Capacity: 1\n",
      "Total Deficit: 25\n",
      "Total Surplus: 23\n",
      "AGENT ID: 1\n",
      "Agent 1 Payloads: 1\n",
      "Agent 1 Max Capacity: 1\n",
      "Total Deficit: 25\n",
      "Total Surplus: 23\n",
      "AGENT ID: 2\n",
      "Agent 2 Payloads: 1\n",
      "Agent 2 Max Capacity: 1\n",
      "Total Deficit: 25\n",
      "Total Surplus: 23\n",
      "AGENT ID: 3\n",
      "Agent 3 Payloads: 0\n",
      "Agent 3 Max Capacity: 1\n",
      "\n",
      " Env search-deliver Algo mappo Exp metric-test updates 1/250 episodes, total num timesteps 40/5000, FPS 6.\n",
      "\n",
      "average episode rewards is -0.9750001132488251\n",
      "wandb due to keyboard interrupt\n"
     ]
    }
   ],
   "source": [
    "main([], parsed_args = all_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "patrolling_zoo2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
